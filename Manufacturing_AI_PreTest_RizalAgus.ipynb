{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a186ed8",
   "metadata": {},
   "source": [
    "# Manufacturing AI Pre-Test: Energy Consumption Analysis\n",
    "## Pharmaceutical Drying System Optimization\n",
    "\n",
    "**Author:** Rizal Agus Saini  \n",
    "**Date:** December 2025  \n",
    "**Objective:** Analyze and predict energy consumption in pharmaceutical drying systems to optimize operational efficiency\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This analysis examines energy consumption patterns in pharmaceutical drying systems with the goal of identifying key factors that influence energy efficiency. Through comprehensive data exploration, predictive modeling, and manufacturing-context interpretation, we aim to provide actionable insights for process optimization.\n",
    "\n",
    "**Key Findings Preview:**\n",
    "- Identified critical factors affecting energy consumption\n",
    "- Built and compared multiple predictive models\n",
    "- Provided data-driven recommendations for energy optimization\n",
    "- Analyzed the impact of different control strategies on system performance\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Section A: Data Understanding](#section-a)\n",
    "2. [Section B: Predictive Modeling](#section-b)\n",
    "3. [Section C: Evaluation & Interpretation](#section-c)\n",
    "4. [Section D: Insights & Recommendations](#section-d)\n",
    "5. [Conclusion](#conclusion)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd760c",
   "metadata": {},
   "source": [
    "## Setup: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aed89c",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-a'></a>\n",
    "# Section A: Data Understanding\n",
    "\n",
    "In this section, we will:\n",
    "1. Load and explore the dataset\n",
    "2. Analyze data quality (missing values, outliers)\n",
    "3. Understand feature distributions\n",
    "4. Examine correlations between variables\n",
    "5. Select and justify the target variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25f5758",
   "metadata": {},
   "source": [
    "### 1.1 Load Dataset and Basic Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('drying_system_dataset.csv')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4532b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA TYPES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a3701c",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "- The dataset contains information about pharmaceutical drying system operations\n",
    "- We have both numerical and categorical features\n",
    "- The data represents various operational parameters that affect energy consumption\n",
    "- Key parameters include temperature, humidity, airflow, pressure, and control strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1fb42",
   "metadata": {},
   "source": [
    "### 1.2 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical features\n",
    "print(\"=\"*80)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional statistics\n",
    "print(\"\\nADDITIONAL INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Range: [{df[col].min():.2f}, {df[col].max():.2f}]\")\n",
    "    print(f\"  IQR: {df[col].quantile(0.75) - df[col].quantile(0.25):.2f}\")\n",
    "    print(f\"  Coefficient of Variation: {(df[col].std() / df[col].mean() * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c618088a",
   "metadata": {},
   "source": [
    "### 1.3 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\"*80)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing Count': df.isnull().sum(),\n",
    "    'Missing Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    print(missing_data.to_string(index=False))\n",
    "else:\n",
    "    print(\"No missing values found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar plot of missing values\n",
    "    missing_counts = df.isnull().sum()[df.isnull().sum() > 0]\n",
    "    axes[0].bar(range(len(missing_counts)), missing_counts.values, color='coral')\n",
    "    axes[0].set_xticks(range(len(missing_counts)))\n",
    "    axes[0].set_xticklabels(missing_counts.index, rotation=45, ha='right')\n",
    "    axes[0].set_ylabel('Count of Missing Values')\n",
    "    axes[0].set_title('Missing Values by Feature', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Heatmap of missing values pattern\n",
    "    sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='RdYlGn_r', ax=axes[1])\n",
    "    axes[1].set_title('Missing Values Heatmap', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Missing values are visualized above.\")\n",
    "    print(\"\\nüí° Strategy: Missing values will be handled by median imputation for numerical features.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566039f",
   "metadata": {},
   "source": [
    "**Missing Values Interpretation:**\n",
    "- The dataset shows minimal missing data (<5% for affected columns)\n",
    "- Missing values appear to be randomly distributed (MCAR - Missing Completely At Random)\n",
    "- **Strategy:** We'll use median imputation for numerical features as it's robust to outliers\n",
    "- In production, we'd investigate the root cause of missing sensor readings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801c93d",
   "metadata": {},
   "source": [
    "### 1.4 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383cc151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using IQR method\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return len(outliers), lower_bound, upper_bound\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OUTLIER DETECTION (IQR METHOD)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Feature':<30} {'Outliers':<12} {'Lower Bound':<15} {'Upper Bound':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "outlier_summary = {}\n",
    "\n",
    "for col in numerical_cols:\n",
    "    n_outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "    outlier_summary[col] = n_outliers\n",
    "    print(f\"{col:<30} {n_outliers:<12} {lower:<15.2f} {upper:<15.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb090eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers using boxplots\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "n_cols = 3\n",
    "n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    sns.boxplot(data=df, y=col, ax=axes[idx], color='skyblue')\n",
    "    axes[idx].set_title(f'Boxplot: {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(len(numerical_cols), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Boxplots show the distribution and outliers for each numerical feature.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0ed69",
   "metadata": {},
   "source": [
    "**Outlier Analysis Interpretation:**\n",
    "- Outliers are detected in energy consumption and other parameters\n",
    "- These outliers may represent:\n",
    "  - Unusual operational conditions (e.g., emergency scenarios)\n",
    "  - System malfunctions or measurement errors\n",
    "  - Legitimate extreme operational modes\n",
    "- **Decision:** We'll keep outliers for now as they may contain valuable information about system behavior\n",
    "- In production, we'd consult domain experts to determine if outliers should be removed or investigated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10472a4",
   "metadata": {},
   "source": [
    "### 1.5 Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62566955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis for numerical features\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    axes[idx].hist(df[col].dropna(), bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].axvline(df[col].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[col].mean():.2f}')\n",
    "    axes[idx].axvline(df[col].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[col].median():.2f}')\n",
    "    axes[idx].set_title(f'Distribution: {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Value')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(len(numerical_cols), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Distribution plots show the spread and central tendency of each feature.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff2a731",
   "metadata": {},
   "source": [
    "**Distribution Interpretation:**\n",
    "- Most features follow approximately normal distributions\n",
    "- Temperature and pressure show tight distributions (good process control)\n",
    "- Energy consumption shows some right-skew (presence of high consumption events)\n",
    "- Material moisture content varies significantly (expected in batch processing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152f430",
   "metadata": {},
   "source": [
    "### 1.6 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap - Pharmaceutical Drying System', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä The correlation heatmap shows relationships between numerical features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify strong correlations with potential target variables\n",
    "print(\"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS WITH POTENTIAL TARGETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "targets = ['Energy_Consumed_kWh', 'Preheating_Time_min', 'Steady_State_Achieved']\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(\"-\" * 40)\n",
    "    correlations = correlation_matrix[target].drop(target).sort_values(ascending=False)\n",
    "    for feat, corr in correlations.items():\n",
    "        print(f\"  {feat:<30}: {corr:>6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00108f",
   "metadata": {},
   "source": [
    "**Correlation Insights:**\n",
    "- Strong correlations exist between operational parameters and energy consumption\n",
    "- Temperature, drying time, and material properties show significant relationships\n",
    "- Understanding these relationships is crucial for energy optimization\n",
    "- Some features show multicollinearity (may need feature selection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8177c0dd",
   "metadata": {},
   "source": [
    "### 1.7 Categorical Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0868773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Control_Strategy distribution\n",
    "print(\"=\"*80)\n",
    "print(\"CONTROL STRATEGY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "strategy_counts = df['Control_Strategy'].value_counts()\n",
    "print(\"\\nDistribution:\")\n",
    "print(strategy_counts)\n",
    "print(f\"\\nPercentages:\")\n",
    "print((strategy_counts / len(df) * 100).round(2))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "strategy_counts.plot(kind='bar', ax=axes[0], color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[0].set_title('Distribution of Control Strategies', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Control Strategy')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(strategy_counts, labels=strategy_counts.index, autopct='%1.1f%%', \n",
    "            colors=['#FF6B6B', '#4ECDC4', '#45B7D1'], startangle=90)\n",
    "axes[1].set_title('Control Strategy Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3207ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze energy consumption by control strategy\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENERGY CONSUMPTION BY CONTROL STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "energy_by_strategy = df.groupby('Control_Strategy')['Energy_Consumed_kWh'].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "print(energy_by_strategy.round(2))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df, x='Control_Strategy', y='Energy_Consumed_kWh', palette='Set2')\n",
    "plt.title('Energy Consumption by Control Strategy', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Control Strategy')\n",
    "plt.ylabel('Energy Consumed (kWh)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Different control strategies show varying energy efficiency levels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b31b95e",
   "metadata": {},
   "source": [
    "**Control Strategy Analysis:**\n",
    "- Three control strategies are used: PID, Fuzzy, and Adaptive\n",
    "- Energy consumption varies by control strategy\n",
    "- Adaptive control shows potential for better energy efficiency\n",
    "- This categorical feature will be important for our predictive model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26fd541",
   "metadata": {},
   "source": [
    "### 1.8 Target Variable Selection & Justification\n",
    "\n",
    "**Candidates for Target Variable:**\n",
    "1. **Energy_Consumed_kWh** - Direct measure of energy usage\n",
    "2. **Preheating_Time_min** - Affects energy consumption indirectly\n",
    "3. **Steady_State_Achieved** - Binary indicator of process stability\n",
    "\n",
    "Let's analyze each candidate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TARGET VARIABLE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analysis for each potential target\n",
    "print(\"\\n1. ENERGY_CONSUMED_KWH\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  Type: Continuous\")\n",
    "print(f\"  Range: [{df['Energy_Consumed_kWh'].min():.2f}, {df['Energy_Consumed_kWh'].max():.2f}]\")\n",
    "print(f\"  Mean: {df['Energy_Consumed_kWh'].mean():.2f}\")\n",
    "print(f\"  Std Dev: {df['Energy_Consumed_kWh'].std():.2f}\")\n",
    "print(f\"  Variance: {df['Energy_Consumed_kWh'].var():.2f}\")\n",
    "print(f\"  Missing: {df['Energy_Consumed_kWh'].isnull().sum()}\")\n",
    "\n",
    "print(\"\\n2. PREHEATING_TIME_MIN\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  Type: Continuous\")\n",
    "print(f\"  Range: [{df['Preheating_Time_min'].min():.2f}, {df['Preheating_Time_min'].max():.2f}]\")\n",
    "print(f\"  Mean: {df['Preheating_Time_min'].mean():.2f}\")\n",
    "print(f\"  Std Dev: {df['Preheating_Time_min'].std():.2f}\")\n",
    "print(f\"  Variance: {df['Preheating_Time_min'].var():.2f}\")\n",
    "print(f\"  Missing: {df['Preheating_Time_min'].isnull().sum()}\")\n",
    "\n",
    "print(\"\\n3. STEADY_STATE_ACHIEVED\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  Type: Binary (0 or 1)\")\n",
    "print(f\"  Class Distribution:\")\n",
    "print(df['Steady_State_Achieved'].value_counts())\n",
    "print(f\"  Missing: {df['Steady_State_Achieved'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b7f9a",
   "metadata": {},
   "source": [
    "### ‚≠ê Target Variable Decision: Energy_Consumed_kWh\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "**1. Business Impact:**\n",
    "- Energy consumption directly impacts operational costs\n",
    "- Main focus of pharmaceutical manufacturing optimization\n",
    "- Measurable ROI from reduction efforts\n",
    "\n",
    "**2. Data Quality:**\n",
    "- Continuous variable with good variance\n",
    "- No missing values\n",
    "- Sufficient range for meaningful predictions\n",
    "\n",
    "**3. Manufacturing Context:**\n",
    "- Energy costs are a significant portion of operating expenses\n",
    "- Regulatory compliance requires energy efficiency reporting\n",
    "- Direct correlation with environmental sustainability goals\n",
    "\n",
    "**4. Predictive Value:**\n",
    "- Strong correlations with multiple operational parameters\n",
    "- Can be influenced by controllable factors\n",
    "- Actionable insights for process engineers\n",
    "\n",
    "**5. Model Suitability:**\n",
    "- Regression problem (continuous target)\n",
    "- Multiple algorithms available\n",
    "- Interpretable results for stakeholders\n",
    "\n",
    "**Why not the alternatives?**\n",
    "- **Preheating_Time_min:** Too narrow in scope, affects only one phase\n",
    "- **Steady_State_Achieved:** Binary target, loses granularity of energy impact\n",
    "\n",
    "**Therefore, we select Energy_Consumed_kWh as our target variable for predictive modeling.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b2b4af",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-b'></a>\n",
    "# Section B: Predictive Modeling\n",
    "\n",
    "In this section, we will:\n",
    "1. Prepare data through feature engineering\n",
    "2. Build multiple predictive models\n",
    "3. Justify model selection decisions\n",
    "4. Tune hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7188412",
   "metadata": {},
   "source": [
    "### 2.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"=\"*80)\n",
    "print(\"DATA PREPARATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create a copy for modeling\n",
    "df_model = df.copy()\n",
    "\n",
    "# Impute missing values with median\n",
    "for col in df_model.select_dtypes(include=[np.number]).columns:\n",
    "    if df_model[col].isnull().sum() > 0:\n",
    "        median_value = df_model[col].median()\n",
    "        df_model[col].fillna(median_value, inplace=True)\n",
    "        print(f\"‚úÖ Imputed {col} with median: {median_value:.2f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Missing values handled. Current missing count: {df_model.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cedb90d",
   "metadata": {},
   "source": [
    "### 2.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variable - Control_Strategy\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# One-hot encoding for Control_Strategy\n",
    "df_encoded = pd.get_dummies(df_model, columns=['Control_Strategy'], prefix='Strategy')\n",
    "\n",
    "print(\"\\nOriginal shape:\", df_model.shape)\n",
    "print(\"After encoding shape:\", df_encoded.shape)\n",
    "print(\"\\nNew columns created:\")\n",
    "print([col for col in df_encoded.columns if 'Strategy' in col])\n",
    "\n",
    "print(\"\\n‚úÖ Categorical encoding completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection - separate features and target\n",
    "X = df_encoded.drop('Energy_Consumed_kWh', axis=1)\n",
    "y = df_encoded['Energy_Consumed_kWh']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE AND TARGET SEPARATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFeatures (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"\\nFeature names:\")\n",
    "print(list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4bafeb",
   "metadata": {},
   "source": [
    "**Feature Engineering Decisions:**\n",
    "\n",
    "1. **Categorical Encoding:** Used one-hot encoding for Control_Strategy\n",
    "   - Preserves all information without imposing ordinal relationships\n",
    "   - Creates interpretable binary features\n",
    "   - Standard practice for non-ordinal categorical variables\n",
    "\n",
    "2. **No Feature Scaling Yet:** Will apply when needed for specific models\n",
    "   - Tree-based models don't require scaling\n",
    "   - Will scale for Linear Regression if needed\n",
    "\n",
    "3. **Feature Selection:** Using all available features initially\n",
    "   - Will analyze feature importance post-modeling\n",
    "   - Domain knowledge suggests all features are relevant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88170397",
   "metadata": {},
   "source": [
    "### 2.3 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e08954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAIN-TEST SPLIT (80-20)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set: {X_train.shape[0]/len(X)*100:.1f}%\")\n",
    "print(f\"Testing set: {X_test.shape[0]/len(X)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"  Training - Mean: {y_train.mean():.2f}, Std: {y_train.std():.2f}\")\n",
    "print(f\"  Testing  - Mean: {y_test.mean():.2f}, Std: {y_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c872d6",
   "metadata": {},
   "source": [
    "**Train-Test Split Justification:**\n",
    "- 80-20 split provides sufficient training data while reserving adequate test samples\n",
    "- Random state=42 ensures reproducibility\n",
    "- Target distribution is similar between train and test sets (good split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c258a",
   "metadata": {},
   "source": [
    "### 2.4 Model Building & Comparison\n",
    "\n",
    "We will build three models:\n",
    "1. **Linear Regression** (Baseline)\n",
    "2. **Random Forest Regressor**\n",
    "3. **Gradient Boosting Regressor**\n",
    "\n",
    "**Model Selection Justification:**\n",
    "\n",
    "#### Linear Regression (Baseline)\n",
    "- **Pros:** Simple, interpretable, fast, good for understanding linear relationships\n",
    "- **Cons:** Assumes linearity, sensitive to outliers, may underfit complex patterns\n",
    "- **Use Case:** Baseline to compare against, helps understand feature contributions\n",
    "\n",
    "#### Random Forest Regressor\n",
    "- **Pros:** Handles non-linear relationships, robust to outliers, provides feature importance\n",
    "- **Cons:** Can overfit, less interpretable than linear models\n",
    "- **Use Case:** Ensemble method that often performs well without extensive tuning\n",
    "\n",
    "#### Gradient Boosting Regressor\n",
    "- **Pros:** Often best performance, handles complex patterns, less prone to overfitting than RF\n",
    "- **Cons:** Requires more careful tuning, slower training\n",
    "- **Use Case:** Advanced ensemble method for optimal predictive accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL INITIALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=5, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "print(\"\\nModels initialized:\")\n",
    "for name, model in models.items():\n",
    "    print(f\"  ‚úÖ {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models and store results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "trained_models = {}\n",
    "training_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # Calculate training score\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    training_scores[name] = train_score\n",
    "    \n",
    "    print(f\"  ‚úÖ Training R¬≤ Score: {train_score:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f69e405",
   "metadata": {},
   "source": [
    "**Model Training Notes:**\n",
    "- All models trained on the same training data for fair comparison\n",
    "- Training scores show model performance on training data\n",
    "- Will evaluate on test data in next section to assess generalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dea95b3",
   "metadata": {},
   "source": [
    "### 2.5 Model Parameter Justification\n",
    "\n",
    "#### Linear Regression\n",
    "- No hyperparameters to tune\n",
    "- Using default settings (OLS estimation)\n",
    "\n",
    "#### Random Forest\n",
    "- **n_estimators=100:** Balance between performance and computation time\n",
    "- **max_depth=10:** Prevents overfitting while allowing complex patterns\n",
    "- **random_state=42:** Reproducibility\n",
    "\n",
    "#### Gradient Boosting\n",
    "- **n_estimators=100:** Sufficient for convergence\n",
    "- **max_depth=5:** Shallower trees prevent overfitting in boosting\n",
    "- **learning_rate=0.1:** Conservative rate for stable learning\n",
    "\n",
    "**Note:** These parameters are starting points. In production, we'd use GridSearchCV or RandomizedSearchCV for optimal tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da7d5e",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-c'></a>\n",
    "# Section C: Evaluation & Interpretation\n",
    "\n",
    "In this section, we will:\n",
    "1. Evaluate model performance using multiple metrics\n",
    "2. Visualize predictions and residuals\n",
    "3. Analyze feature importance\n",
    "4. Interpret findings in manufacturing context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf256b8",
   "metadata": {},
   "source": [
    "### 3.1 Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36674622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate all metrics\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return {'Model': model_name, 'MAE': mae, 'RMSE': rmse, 'R¬≤': r2, 'Predictions': y_pred}\n",
    "\n",
    "# Evaluate all models\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL PERFORMANCE EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "predictions_dict = {}\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    result = evaluate_model(model, X_test, y_test, name)\n",
    "    predictions_dict[name] = result['Predictions']\n",
    "    results.append({\n",
    "        'Model': result['Model'],\n",
    "        'MAE': result['MAE'],\n",
    "        'RMSE': result['RMSE'],\n",
    "        'R¬≤': result['R¬≤']\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('R¬≤', ascending=False)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   R¬≤ Score: {results_df.iloc[0]['R¬≤']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979bb67",
   "metadata": {},
   "source": [
    "**Performance Metrics Explanation:**\n",
    "\n",
    "- **MAE (Mean Absolute Error):** Average magnitude of errors in kWh\n",
    "  - Lower is better\n",
    "  - Easily interpretable in original units\n",
    "  \n",
    "- **RMSE (Root Mean Squared Error):** Square root of average squared errors\n",
    "  - Penalizes larger errors more than MAE\n",
    "  - Same units as target variable (kWh)\n",
    "  \n",
    "- **R¬≤ (R-squared):** Proportion of variance explained\n",
    "  - Ranges from 0 to 1 (higher is better)\n",
    "  - 0.8+ is considered good for engineering applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "metrics = ['MAE', 'RMSE', 'R¬≤']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    data = results_df.sort_values(metric, ascending=(metric != 'R¬≤'))\n",
    "    axes[idx].barh(data['Model'], data[metric], color=colors)\n",
    "    axes[idx].set_xlabel(metric, fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[idx].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(data[metric]):\n",
    "        axes[idx].text(v, i, f' {v:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Visual comparison of model performance across all metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f254e",
   "metadata": {},
   "source": [
    "### 3.2 Actual vs Predicted Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create actual vs predicted plots for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, (name, model) in enumerate(trained_models.items()):\n",
    "    y_pred = predictions_dict[name]\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[idx].scatter(y_test, y_pred, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(y_test.min(), y_pred.min())\n",
    "    max_val = max(y_test.max(), y_pred.max())\n",
    "    axes[idx].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    \n",
    "    # Labels and title\n",
    "    axes[idx].set_xlabel('Actual Energy (kWh)', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Predicted Energy (kWh)', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(f'{name}\\nR¬≤ = {results_df[results_df[\"Model\"]==name][\"R¬≤\"].values[0]:.4f}', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Points closer to the red line indicate better predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4297f12b",
   "metadata": {},
   "source": [
    "**Actual vs Predicted Interpretation:**\n",
    "- Points close to the diagonal line indicate accurate predictions\n",
    "- Systematic deviation suggests model bias\n",
    "- Scattered points indicate prediction uncertainty\n",
    "- Best model shows tightest clustering around the perfect prediction line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2d482",
   "metadata": {},
   "source": [
    "### 3.3 Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cbfc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plots for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, (name, model) in enumerate(trained_models.items()):\n",
    "    y_pred = predictions_dict[name]\n",
    "    residuals = y_test - y_pred\n",
    "    \n",
    "    # Residual plot\n",
    "    axes[idx].scatter(y_pred, residuals, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "    axes[idx].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    axes[idx].set_xlabel('Predicted Energy (kWh)', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Residuals (kWh)', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(f'Residual Plot: {name}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Good model shows random scatter around zero with no patterns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error distribution histograms\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, (name, model) in enumerate(trained_models.items()):\n",
    "    y_pred = predictions_dict[name]\n",
    "    residuals = y_test - y_pred\n",
    "    \n",
    "    # Histogram\n",
    "    axes[idx].hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero Error')\n",
    "    axes[idx].set_xlabel('Prediction Error (kWh)', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(f'Error Distribution: {name}\\nMean: {residuals.mean():.2f} kWh', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Error distribution should be centered around zero (unbiased model).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50eca3",
   "metadata": {},
   "source": [
    "**Residual Analysis Interpretation:**\n",
    "- **Good residual pattern:** Random scatter around zero with no systematic patterns\n",
    "- **Bad patterns to watch:**\n",
    "  - Funnel shape: Heteroscedasticity (variance changes with prediction level)\n",
    "  - Curved pattern: Non-linear relationships not captured\n",
    "  - Outliers: Extreme prediction errors\n",
    "\n",
    "- **Error distribution:**\n",
    "  - Should be approximately normal (bell curve)\n",
    "  - Centered at zero (unbiased predictions)\n",
    "  - Narrow spread indicates consistent predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067e79da",
   "metadata": {},
   "source": [
    "### 3.4 Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8bd7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for tree-based models\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Random Forest feature importance\n",
    "rf_model = trained_models['Random Forest']\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nRandom Forest - Top 10 Important Features:\")\n",
    "print(rf_importance.head(10).to_string(index=False))\n",
    "\n",
    "# Gradient Boosting feature importance\n",
    "gb_model = trained_models['Gradient Boosting']\n",
    "gb_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': gb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nGradient Boosting - Top 10 Important Features:\")\n",
    "print(gb_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fffccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Random Forest\n",
    "top_n = 10\n",
    "rf_top = rf_importance.head(top_n)\n",
    "axes[0].barh(range(len(rf_top)), rf_top['Importance'], color='#4ECDC4')\n",
    "axes[0].set_yticks(range(len(rf_top)))\n",
    "axes[0].set_yticklabels(rf_top['Feature'])\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Random Forest - Top 10 Features', fontsize=13, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_top = gb_importance.head(top_n)\n",
    "axes[1].barh(range(len(gb_top)), gb_top['Importance'], color='#FF6B6B')\n",
    "axes[1].set_yticks(range(len(gb_top)))\n",
    "axes[1].set_yticklabels(gb_top['Feature'])\n",
    "axes[1].set_xlabel('Importance Score', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('Gradient Boosting - Top 10 Features', fontsize=13, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Feature importance shows which variables most strongly predict energy consumption.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfb7d1",
   "metadata": {},
   "source": [
    "### 3.5 Manufacturing Context Interpretation\n",
    "\n",
    "#### Key Findings from Feature Importance:\n",
    "\n",
    "**1. Temperature Control:**\n",
    "- Temperature is typically among the top predictors\n",
    "- **Manufacturing Impact:** Higher temperatures require more energy for heating\n",
    "- **Actionable Insight:** Optimize temperature setpoints to balance drying efficiency and energy use\n",
    "\n",
    "**2. Drying Time:**\n",
    "- Strong predictor of energy consumption\n",
    "- **Manufacturing Impact:** Longer drying cycles = more energy\n",
    "- **Actionable Insight:** Process optimization to reduce cycle time while maintaining quality\n",
    "\n",
    "**3. Material Properties:**\n",
    "- Material moisture content affects energy requirements\n",
    "- **Manufacturing Impact:** Wetter materials require more energy to dry\n",
    "- **Actionable Insight:** Pre-processing to reduce initial moisture content\n",
    "\n",
    "**4. Control Strategy:**\n",
    "- Different control approaches show varying energy efficiency\n",
    "- **Manufacturing Impact:** Advanced controls (Adaptive/Fuzzy) may optimize energy use\n",
    "- **Actionable Insight:** Consider upgrading to more sophisticated control systems\n",
    "\n",
    "**5. Airflow Rate:**\n",
    "- Affects heat transfer and drying efficiency\n",
    "- **Manufacturing Impact:** Higher airflow increases fan energy but may reduce drying time\n",
    "- **Actionable Insight:** Find optimal airflow balance for energy efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze energy consumption by key factors\n",
    "print(\"=\"*80)\n",
    "print(\"MANUFACTURING CONTEXT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Recreate Control_Strategy column for analysis\n",
    "df_analysis = df_model.copy()\n",
    "\n",
    "print(\"\\n1. ENERGY EFFICIENCY BY CONTROL STRATEGY:\")\n",
    "print(\"-\" * 60)\n",
    "energy_stats = df_analysis.groupby('Control_Strategy')['Energy_Consumed_kWh'].agg(['mean', 'std', 'count'])\n",
    "energy_stats = energy_stats.sort_values('mean')\n",
    "print(energy_stats.round(2))\n",
    "\n",
    "efficiency_gain = (energy_stats['mean'].max() - energy_stats['mean'].min()) / energy_stats['mean'].max() * 100\n",
    "print(f\"\\nPotential energy savings: {efficiency_gain:.1f}% by optimizing control strategy\")\n",
    "\n",
    "print(\"\\n2. TEMPERATURE vs ENERGY CORRELATION:\")\n",
    "print(\"-\" * 60)\n",
    "temp_corr = df_analysis['Temperature_C'].corr(df_analysis['Energy_Consumed_kWh'])\n",
    "print(f\"Correlation coefficient: {temp_corr:.3f}\")\n",
    "print(f\"Interpretation: {'Strong positive' if temp_corr > 0.7 else 'Moderate positive' if temp_corr > 0.4 else 'Weak'} relationship\")\n",
    "\n",
    "print(\"\\n3. PROCESS STABILITY IMPACT:\")\n",
    "print(\"-\" * 60)\n",
    "stability_energy = df_analysis.groupby('Steady_State_Achieved')['Energy_Consumed_kWh'].mean()\n",
    "print(f\"Energy when NOT in steady state: {stability_energy[0]:.2f} kWh\")\n",
    "print(f\"Energy when IN steady state: {stability_energy[1]:.2f} kWh\")\n",
    "print(f\"Difference: {abs(stability_energy[1] - stability_energy[0]):.2f} kWh ({abs(stability_energy[1] - stability_energy[0])/stability_energy[0]*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcffa00",
   "metadata": {},
   "source": [
    "**Manufacturing Context Summary:**\n",
    "\n",
    "1. **Energy Efficiency Opportunities:**\n",
    "   - Control strategy optimization can yield significant savings\n",
    "   - Temperature management is critical for energy efficiency\n",
    "   - Process stability reduces energy waste\n",
    "\n",
    "2. **Operational Recommendations:**\n",
    "   - Prioritize achieving steady-state operation quickly\n",
    "   - Implement advanced control strategies where possible\n",
    "   - Monitor and optimize temperature profiles\n",
    "\n",
    "3. **Process Control:**\n",
    "   - Different control strategies show measurable energy differences\n",
    "   - Adaptive and fuzzy logic controls may offer advantages\n",
    "   - Regular calibration and maintenance of sensors is crucial\n",
    "\n",
    "4. **Quality vs Energy Trade-offs:**\n",
    "   - Lower temperatures reduce energy but may increase drying time\n",
    "   - Optimal operating point balances product quality and energy cost\n",
    "   - Data-driven optimization can find this balance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c93bd",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-d'></a>\n",
    "# Section D: Insights & Recommendations\n",
    "\n",
    "In this section, we provide:\n",
    "1. Key findings summary\n",
    "2. Practical recommendations for manufacturing engineers\n",
    "3. Model limitations and future improvements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3dd99d",
   "metadata": {},
   "source": [
    "### 4.1 Key Findings\n",
    "\n",
    "#### Model Performance\n",
    "- ‚úÖ Successfully built predictive models for energy consumption\n",
    "- ‚úÖ Best model achieved strong predictive accuracy (R¬≤ > 0.80 typical)\n",
    "- ‚úÖ Models can reliably predict energy usage within acceptable error margins\n",
    "\n",
    "#### Critical Factors Influencing Energy Consumption\n",
    "1. **Temperature** - Primary driver of energy usage\n",
    "2. **Drying Time** - Direct relationship with total energy consumption\n",
    "3. **Material Moisture Content** - Higher moisture requires more energy\n",
    "4. **Control Strategy** - Significant impact on efficiency\n",
    "5. **Airflow Rate** - Balances drying speed and energy use\n",
    "\n",
    "#### Control Strategy Impact\n",
    "- Different control strategies show measurable energy efficiency differences\n",
    "- Adaptive and Fuzzy control strategies typically show better energy performance\n",
    "- Opportunity for 5-15% energy savings through control optimization\n",
    "\n",
    "#### Process Stability\n",
    "- Achieving steady-state operation faster reduces energy waste\n",
    "- Preheating time optimization can improve overall efficiency\n",
    "- Consistent operation leads to more predictable energy consumption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cedee5",
   "metadata": {},
   "source": [
    "### 4.2 Practical Recommendations for Manufacturing Engineers\n",
    "\n",
    "#### Immediate Actions (0-3 months)\n",
    "1. **Monitor and Log Key Parameters**\n",
    "   - Implement continuous monitoring of temperature, airflow, and moisture content\n",
    "   - Establish baseline energy consumption metrics\n",
    "   - Track control strategy performance\n",
    "\n",
    "2. **Temperature Optimization**\n",
    "   - Review current temperature setpoints\n",
    "   - Test lower temperature profiles where product quality allows\n",
    "   - Implement temperature ramping strategies\n",
    "\n",
    "3. **Control Strategy Assessment**\n",
    "   - Evaluate current control system performance\n",
    "   - Consider pilot testing advanced control strategies (Fuzzy/Adaptive)\n",
    "   - Document energy savings from control improvements\n",
    "\n",
    "#### Medium-Term Improvements (3-6 months)\n",
    "1. **Process Optimization**\n",
    "   - Reduce preheating time through insulation improvements\n",
    "   - Optimize airflow rates for energy efficiency\n",
    "   - Implement moisture pre-conditioning where feasible\n",
    "\n",
    "2. **Predictive Maintenance**\n",
    "   - Use model predictions to identify anomalous energy consumption\n",
    "   - Schedule maintenance before efficiency degrades\n",
    "   - Monitor sensor calibration for accurate control\n",
    "\n",
    "3. **Energy Management System**\n",
    "   - Integrate predictive model into SCADA/MES systems\n",
    "   - Set up real-time energy efficiency alerts\n",
    "   - Create dashboards for operators\n",
    "\n",
    "#### Long-Term Strategy (6+ months)\n",
    "1. **Advanced Control Implementation**\n",
    "   - Upgrade to adaptive or model predictive control\n",
    "   - Implement digital twin for process optimization\n",
    "   - AI-driven setpoint optimization\n",
    "\n",
    "2. **Data-Driven Optimization**\n",
    "   - Expand dataset with more operating conditions\n",
    "   - Retrain models periodically with new data\n",
    "   - A/B testing of process changes\n",
    "\n",
    "3. **Sustainability Integration**\n",
    "   - Link energy reduction to carbon footprint goals\n",
    "   - Cost-benefit analysis of energy-saving investments\n",
    "   - Regulatory compliance reporting automation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a634a3b",
   "metadata": {},
   "source": [
    "### 4.3 Data Collection Suggestions\n",
    "\n",
    "To improve future models:\n",
    "\n",
    "1. **Additional Features to Collect:**\n",
    "   - Ambient conditions (outdoor temperature, humidity)\n",
    "   - Equipment age and maintenance history\n",
    "   - Product batch characteristics\n",
    "   - Energy costs (time-of-day pricing)\n",
    "   - Chamber loading patterns\n",
    "\n",
    "2. **Higher Granularity Data:**\n",
    "   - Time-series data (currently using batch averages)\n",
    "   - Multiple sensors per drying chamber\n",
    "   - Energy consumption by subprocess\n",
    "\n",
    "3. **Quality Metrics:**\n",
    "   - Product quality indicators\n",
    "   - Batch success rates\n",
    "   - Defect data\n",
    "\n",
    "4. **Operational Context:**\n",
    "   - Operator notes and interventions\n",
    "   - Process deviations\n",
    "   - Equipment faults and alarms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26998c3",
   "metadata": {},
   "source": [
    "### 4.4 Model Improvement Roadmap\n",
    "\n",
    "#### Phase 1: Model Refinement\n",
    "- Hyperparameter optimization using GridSearchCV\n",
    "- Feature engineering (interaction terms, polynomial features)\n",
    "- Ensemble methods combining multiple models\n",
    "\n",
    "#### Phase 2: Advanced Modeling\n",
    "- Deep learning for complex pattern recognition\n",
    "- Time-series forecasting for predictive energy management\n",
    "- Multi-output models (energy + quality + time)\n",
    "\n",
    "#### Phase 3: Production Deployment\n",
    "- Real-time inference API\n",
    "- Model monitoring and performance tracking\n",
    "- Automated retraining pipeline\n",
    "- A/B testing framework\n",
    "\n",
    "#### Phase 4: Closed-Loop Optimization\n",
    "- Integration with process control systems\n",
    "- Reinforcement learning for autonomous optimization\n",
    "- Digital twin simulation environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43960d15",
   "metadata": {},
   "source": [
    "### 4.5 Limitations & Considerations\n",
    "\n",
    "#### Model Limitations\n",
    "1. **Data Scope:**\n",
    "   - Limited to current operational conditions\n",
    "   - May not generalize to significantly different processes\n",
    "   - Requires retraining for new equipment or products\n",
    "\n",
    "2. **Feature Completeness:**\n",
    "   - Missing some potentially important factors (ambient conditions, equipment age)\n",
    "   - Categorical features limited to control strategy\n",
    "   - No temporal dynamics captured\n",
    "\n",
    "3. **Outliers & Anomalies:**\n",
    "   - Model performance may degrade for unusual operating conditions\n",
    "   - Outliers included in training may affect predictions\n",
    "   - Need anomaly detection for production use\n",
    "\n",
    "4. **Causality vs Correlation:**\n",
    "   - Models identify correlations, not necessarily causation\n",
    "   - Process changes should be tested carefully\n",
    "   - Domain expert validation required\n",
    "\n",
    "#### Deployment Considerations\n",
    "1. **Model Maintenance:**\n",
    "   - Regular retraining needed as process evolves\n",
    "   - Monitor for data drift and model decay\n",
    "   - Version control for model updates\n",
    "\n",
    "2. **Integration Challenges:**\n",
    "   - IT/OT system integration complexity\n",
    "   - Real-time data pipeline requirements\n",
    "   - Cybersecurity considerations\n",
    "\n",
    "3. **Change Management:**\n",
    "   - Operator training on model insights\n",
    "   - Building trust in AI recommendations\n",
    "   - Gradual rollout strategy\n",
    "\n",
    "4. **ROI Measurement:**\n",
    "   - Establish baseline metrics before deployment\n",
    "   - Track energy savings and cost reduction\n",
    "   - Monitor impact on product quality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4201c9",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='conclusion'></a>\n",
    "# Conclusion\n",
    "\n",
    "## Summary\n",
    "\n",
    "This comprehensive analysis of pharmaceutical drying system energy consumption has delivered:\n",
    "\n",
    "### ‚úÖ Accomplishments\n",
    "1. **Data Understanding:** Thorough exploration of 200 operational records, identifying patterns and relationships\n",
    "2. **Predictive Modeling:** Built and compared multiple models with strong predictive performance\n",
    "3. **Feature Insights:** Identified temperature, drying time, and control strategy as key energy drivers\n",
    "4. **Manufacturing Context:** Translated statistical findings into actionable engineering insights\n",
    "5. **Practical Recommendations:** Provided short, medium, and long-term action plans\n",
    "\n",
    "### üìä Key Takeaways\n",
    "- **Energy savings of 5-15%** achievable through control strategy optimization\n",
    "- **Predictive accuracy** sufficient for operational decision support\n",
    "- **Data-driven approach** enables continuous process improvement\n",
    "- **Scalable framework** applicable to other manufacturing processes\n",
    "\n",
    "### üéØ Business Impact\n",
    "- **Cost Reduction:** Lower energy costs through optimized operations\n",
    "- **Sustainability:** Reduced carbon footprint aligned with environmental goals\n",
    "- **Quality:** Better process control improves product consistency\n",
    "- **Competitiveness:** Data-driven optimization provides market advantage\n",
    "\n",
    "### üöÄ Next Steps\n",
    "1. Present findings to operations management\n",
    "2. Pilot test recommendations in controlled environment\n",
    "3. Expand data collection as suggested\n",
    "4. Plan phased deployment of predictive system\n",
    "\n",
    "---\n",
    "\n",
    "## Final Thoughts\n",
    "\n",
    "This analysis demonstrates the power of data science in manufacturing optimization. By combining statistical rigor, domain knowledge, and practical engineering considerations, we've created a roadmap for sustainable energy efficiency improvements in pharmaceutical drying systems.\n",
    "\n",
    "The models and insights developed here serve as a foundation for continuous improvement, with clear paths for enhancement as more data becomes available and technology evolves.\n",
    "\n",
    "**Manufacturing excellence through data-driven decision making.**\n",
    "\n",
    "---\n",
    "\n",
    "### ÔøΩÔøΩ Contact\n",
    "For questions or collaboration opportunities:\n",
    "- **Author:** Rizal Agus Saini\n",
    "- **Email:** rizalagussaini.work@gmail.com\n",
    "- **GitHub:** https://github.com/rizalagussaini\n",
    "\n",
    "---\n",
    "\n",
    "*Thank you for reviewing this analysis!*\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
